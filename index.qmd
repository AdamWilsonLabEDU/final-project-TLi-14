---
title: "My Final Project Template"
author: Tianze Li
subtitle: Subtitle here if desired
date: today
date-format: long
---

# Introduction

\[\~ 200 words\]

Clearly stated background and questions / hypotheses / problems being addressed. Sets up the analysis in an interesting and compelling way. Include figures if you like.

# Materials and methods

\[\~ 200 words\]

Narrative: Clear narrative description of the data sources and methods. Includes data from at least two sources that were integrated / merged in R.

Code: The code associated with the project is well organized and easy to follow. Demonstrates mastery of R graphics and functions.

Data: The underlying data are publicly accessible via the web and downloaded/accessed within the Rmd script. If you want to use your own data, you must make it available on a website (e.g. Figshare) so that others are able to re-run your code.

You can do bullets like this:

-   The first most important thing
-   The second most important thing
-   The third most important thing

You can do numbers like this:

1.  The first most important thing
2.  The second most important thing
3.  The third most important thing

See <http://rmarkdown.rstudio.com/> for all the amazing things you can do.

1. Setup and Download Environmental data
```{r setup, include=FALSE}
# Install and load necessary packages
# install.packages(c("terra", "geodata"))
library(terra)
library(geodata)

# Specify the download path
download_path <- "E:/UB_Master/24fall/GEO511 Spatial/Final_project/Final_Project"

# Download elevation data (Elevation)
elevation <- worldclim_global(var = "elev", res = 2.5, path = download_path) 

# Check and visualize the elevation data
print(elevation)
plot(elevation, main = "Global Elevation (2.5min)")

# Download Bioclimatic variables data
# WorldClim Bioclimatic variables (typically from bio1 to bio19)
bioclimatic_vars <- worldclim_global(var = "bio", res = 2.5, path = download_path)  

# Check and visualize Bioclimatic variables data
print(bioclimatic_vars)
plot(bioclimatic_vars[[1]], main = "Bio1: Annual Mean Temperature")

# Combine the elevation data and Bioclimatic variables into one raster stack
climate_stack <- c(elevation, bioclimatic_vars)  

# Check and visualize the merged raster stack
print(climate_stack)
plot(climate_stack[[1]], main = "Elevation and Bioclimatic Variables")
```

```{r, message=F, warning=F}
# Load necessary libraries
# install.packages("rnaturalearth")
library(terra)
library(rnaturalearth)

# Load or create the climate and elevation raster stack
# Assuming climate_stack has already been created

# Step 1: Download global land shapefile
land <- ne_download(scale = "medium", type = "land", category = "physical", returnclass = "sf")

# Step 2: Crop and mask raster stack to include only land areas
climate_stack_cropped <- crop(climate_stack, ext(land))  # Crop to land extent
climate_stack_land <- mask(climate_stack_cropped, vect(land))  # Mask to land areas

# Step 3: Visualize the results
plot(climate_stack_land[[1]], main = "Cropped and Masked Climate Data (Land Only)")
```

2. Crop and Mask Raster Stack for Land Areas
```{r}

# Load necessary libraries
# install.packages("rnaturalearth")
library(terra)
library(rnaturalearth)

# Load or create the climate and elevation raster stack
# Assuming climate_stack has already been created

# Download global land shapefile
land <- ne_download(scale = "medium", type = "land", category = "physical", returnclass = "sf")

# Crop and mask raster stack to include only land areas
climate_stack_cropped <- crop(climate_stack, ext(land))  # Crop to land extent
climate_stack_land <- mask(climate_stack_cropped, vect(land))  # Mask to land areas

# Visualize the results
plot(climate_stack_land[[1]], main = "Cropped and Masked Elevation (Land Only)")

```

3. Prepare Takakia Occurrence Data
```{r}
# Install and load rgbif
# install.packages("rgbif")
library(rgbif)

# Define the species name
species_name <- "Takakia S.Hatt. & Inoue"

# Retrieve occurrence data
gbif_data <- occ_search(scientificName = species_name, limit = 2000)

# Extract longitude and latitude from the data
occurrences <- data.frame(
  lon = gbif_data$data$decimalLongitude,
  lat = gbif_data$data$decimalLatitude
)

# Remove rows with missing coordinates
occurrences_clean <- na.omit(occurrences)

# Remove duplicate coordinates
occurrences_unique <- occurrences_clean[!duplicated(occurrences_clean), ]

# Check the number of unique points
cat("Number of unique occurrence points:", nrow(occurrences_unique), "\n")

# Install and load ggplot2
# install.packages("ggplot2")
library(ggplot2)

# Plot unique occurrence points
ggplot() +
  geom_point(data = occurrences_unique, aes(x = lon, y = lat), color = "red", size = 1) +
  theme_minimal() +
  labs(title = "Unique Distribution Points of Takakia S.Hatt. & Inoue",
       x = "Longitude",
       y = "Latitude")

# Save the unique occurrence data to a CSV file
write.csv(occurrences_unique, "Takakia_Unique_Distribution_Data.csv", row.names = FALSE)

```

4. MaxEnt Model for Takakia Distribution Prediction
```{r}
# Install required packages (if not already installed)
# install.packages(c("dismo", "rJava"))
library(dismo)
library(terra)
library(sf)
library(rJava)
library(raster)

options(java.parameters = "-Xmx8g")

# Assuming climate_stack_land is prepared and cleaned (using all layers in the stack)
# No need to subset the layers as we will use all the variables from climate_stack_land
selected_env_stack <- climate_stack_land

# Ensure occurrences_unique is an sf object with coordinates
occurrences_sf <- st_as_sf(occurrences_unique, coords = c("lon", "lat"), crs = crs(selected_env_stack))

# Convert SpatRaster to RasterStack (if it's not already in stack format)
selected_env_stack <- stack(selected_env_stack)

# Extract coordinates from the sf object
occurrences_matrix <- as.matrix(st_coordinates(occurrences_sf))

# Extract environmental values at occurrence points
env_values <- extract(selected_env_stack, occurrences_matrix)

# Combine occurrences with extracted environmental data
occ_with_env <- cbind(occurrences_matrix, env_values)

# Remove rows with NA predictor values
occ_with_env <- na.omit(occ_with_env)

# Separate cleaned occurrences and predictor values
occurrences_matrix_clean <- occ_with_env[, 1:2]  # First two columns are longitude and latitude

# Train the MaxEnt model (with all variables)
maxent_model <- maxent(
  x = selected_env_stack, 
  p = occurrences_matrix_clean
)

# Summary of the model
summary(maxent_model)

# Predict the current distribution
current_distribution <- predict(maxent_model, selected_env_stack)

# Visualize the prediction
plot(current_distribution, main = "Predicted Current Distribution of Takakia")

# Save the predicted distribution as a GeoTIFF file
writeRaster(current_distribution, filename = "Takakia_Current_Distribution.tif", overwrite = TRUE)

# Split data into training and testing sets
set.seed(123)
train_indices <- sample(1:nrow(occurrences_matrix), size = 0.7 * nrow(occurrences_matrix))
train_data <- occurrences_matrix[train_indices, ]
test_data <- occurrences_matrix[-train_indices, ]

# Evaluate the model
eval <- evaluate(maxent_model, p = train_data, a = test_data, x = selected_env_stack)
print(eval)

# Plot the receiver operating characteristic (ROC) curve
plot(eval, "ROC")

# Perform Jackknife to evaluate the importance of each environmental variable
# Use the 'maxent' model with jackknife = TRUE
jackknife_results <- dismo::maxent(
  x = selected_env_stack, 
  p = occurrences_matrix_clean,
  jackknife = TRUE
)

# Extract Jackknife results from the 'maxent' object using the appropriate method
# Jackknife results are contained in the model object itself, accessible by using the 'maxent' method:
jackknife_importance <- jackknife_results@results

# Display the Jackknife importance values for each variable
print(jackknife_importance)
```

Add any additional processing steps here.

# Results

\[\~200 words\]

Tables and figures (maps and other graphics) are carefully planned to convey the results of your analysis. Intense exploration and evidence of many trials and failures. The author looked at the data in many different ways before coming to the final presentation of the data.

Show tables, plots, etc. and describe them.

```{r, fig.width=6, fig.height=3, fig.cap="Map of completely random data"}
m <- leaflet(data) %>% 
  addTiles() %>% 
  addCircleMarkers(~x, ~y, radius = ~size,color = ~as.factor(category)) %>% 
  addPopups(~x[2], ~y[2], "Random popup")
m  # a map with the default OSM tile layer
```

```{r}
data %>% 
  ggplot(aes(x=x,y=y,col=category))+
  geom_point()
```

### Dygraphs Example

```{r}
library(dygraphs)
dygraph(nhtemp, main = "New Haven Temperatures") |> 
  dyRangeSelector(dateWindow = c("1920-01-01", "1960-01-01")) 
```

# Conclusions

\[\~200 words\]

Clear summary adequately describing the results and putting them in context. Discussion of further questions and ways to continue investigation.

# References

All sources are cited in a consistent manner
