[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Predicting the Distribution of an Enigmatic Genus of Moss",
    "section": "",
    "text": "Takakia (Figure 1) was discovered in the Himalayas in 1861. It is the oldest known extant genus of land plants, estimated to have branched off the other mosses around 390 million years ago. Takakia has rapidly evolving genes and is highly sensitive to environmental changes, particularly to temperatures during the growing season. Based on 20 years of monitoring Takakia on the Tibetan Plateau, scientists have discovered that due to climate change, including glacier melt and rising annual average temperatures, this species is facing the risk of extinction in the region. This highlights the urgent need for an effective conservation plan for Takakia.\nHowever, due to Takakia’s small size and its primary growth between rocks, it is difficult to discover. Most research on Takakia focuses on the genetic response of Takakia to environmental changes. There is lack of studies that focus on distribution of Takakia on a global scale.\nIn this project, I aim to address this gap by utilizing global environmental data to predict suitable growing areas for Takakia worldwide. I hope that the results of the project will provide a reference for the establishment of conservation areas for Takakia in the future and the selection of Ex-situ conservation location.\n\n\n\nFigure 1"
  },
  {
    "objectID": "index.html#data-source",
    "href": "index.html#data-source",
    "title": "Predicting the Distribution of an Enigmatic Genus of Moss",
    "section": "Data / Source",
    "text": "Data / Source\n\n\n\nData / Source\nDescription / Link\n\n\n\n\nWorld Takakia occurrences record\nGlobal Biodiversity Information Facility(GBIF)\n\n\nTakakia field samples\nField study\n\n\nHistorical climate data\n19 Bioclimatic variables\n\n\n\nI used the above data to predict the global spatial distribution of Takakia using the Maximum Entropy(MaxEnt) method in R. The specific implementation code is as follows:\n\nInstall and Load Packages\n\n\n\nShow Me the Script\nlibrary(terra)\nlibrary(geodata)\nlibrary(rnaturalearth)\nlibrary(rgbif)\nlibrary(ggplot2)\nlibrary(rnaturalearthdata)\nlibrary(dismo)\nlibrary(sf)\nlibrary(rJava)\nlibrary(raster)\n\n\n1. Setup and Download Environmental data\n\n\n\nGlobal Elevation\n\n\n\n\n\nBio1: Annual Mean Temperature\n\n\n\n\nShow Me the Script\n# Specify the download path\ndownload_path &lt;- \"E:/UB_Master/24fall/GEO511 Spatial/Final_project/Final_Project\"\n\n# Download elevation data (Elevation)\nelevation &lt;- worldclim_global(var = \"elev\", res = 2.5, path = download_path) \n\n# Download Bioclimatic variables data\n# WorldClim Bioclimatic variables (typically from bio1 to bio19)\nbioclimatic_vars &lt;- worldclim_global(var = \"bio\", res = 2.5, path = download_path)  \n\n# Check and visualize Bioclimatic variables data\nprint(bioclimatic_vars)\nplot(bioclimatic_vars[[1]], main = \"Bio1: Annual Mean Temperature\")\n\n# Combine the elevation data and Bioclimatic variables into one raster stack\nclimate_stack &lt;- c(elevation, bioclimatic_vars)  \n\n# Check and visualize the merged raster stack\nprint(climate_stack)\nplot(climate_stack[[1]], main = \"Global Elevation\")\n\n\n2. Crop and Mask Raster Stack for Land Areas\n\n\n\nBio12: Annual Precipitation\n\n\n\n\nShow Me the Script\n# Download global land shapefile\nland &lt;- ne_download(scale = \"medium\", type = \"land\", category = \"physical\", returnclass = \"sf\")\n\n# Crop and mask raster stack to include only land areas\nclimate_stack_cropped &lt;- crop(climate_stack, ext(land))\nclimate_stack_land &lt;- mask(climate_stack_cropped, vect(land))\n\n# Visualize the results\nplot(climate_stack_land[[12]], main = \"Annual Precipitation(Land Only)\")\n\n\n3. Prepare Takakia Occurrence Data\n\n\n\nOccurrences of Takakia\n\n\n\n\nShow Me the Script\n# Define the species name\nspecies_name &lt;- \"Takakia S.Hatt. & Inoue\"\n\n# Retrieve occurrence data\ngbif_data &lt;- occ_search(scientificName = species_name, limit = 2000)\n\n# Extract longitude and latitude from the data\noccurrences &lt;- data.frame(\n  lon = gbif_data$data$decimalLongitude,\n  lat = gbif_data$data$decimalLatitude\n)\n\n# Remove rows with missing coordinates\noccurrences_clean &lt;- na.omit(occurrences)\n\n# Remove duplicate coordinates\noccurrences_unique &lt;- occurrences_clean[!duplicated(occurrences_clean), ]\n\n# Check the number of unique points\ncat(\"Number of unique occurrence points:\", nrow(occurrences_unique), \"\\n\")\n\n# Load world map for background\nworld_map &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\n# Plot unique occurrence points\nggplot() +\n  geom_sf(data = world_map, fill = \"lightgray\", color = \"black\") +\n  geom_point(data = occurrences_unique, aes(x = lon, y = lat), color = \"red\", size = 1) +\n  theme_minimal() +\n  labs(title = \"Unique Distribution Points of Takakia S.Hatt. & Inoue\",\n       x = \"Longitude\",\n       y = \"Latitude\")\n\n# Save the unique occurrence data to a CSV file\nwrite.csv(occurrences_unique, \"Takakia_Unique_Distribution_Data.csv\", row.names = FALSE)\n\n\n4. MaxEnt Model for Takakia Distribution Prediction\n\n\nShow Me the Script\noptions(java.parameters = \"-Xmx8g\")\n\nselected_env_stack &lt;- climate_stack_land\n\n# Ensure occurrences_unique is an sf object with coordinates\noccurrences_sf &lt;- st_as_sf(occurrences_unique, coords = c(\"lon\", \"lat\"), crs = crs(selected_env_stack))\n\n# Convert SpatRaster to RasterStack (if it's not already in stack format)\nselected_env_stack &lt;- stack(selected_env_stack)\n\n# Extract coordinates from the sf object\noccurrences_matrix &lt;- as.matrix(st_coordinates(occurrences_sf))\n\n# Extract environmental values at occurrence points\nenv_values &lt;- extract(selected_env_stack, occurrences_matrix)\n\n# Combine occurrences with extracted environmental data\nocc_with_env &lt;- cbind(occurrences_matrix, env_values)\n\n# Remove rows with NA predictor values\nocc_with_env &lt;- na.omit(occ_with_env)\n\n# Separate cleaned occurrences and predictor values\noccurrences_matrix_clean &lt;- occ_with_env[, 1:2]  # First two columns are longitude and latitude\n\n# Train the MaxEnt model (with all variables)\nmaxent_model &lt;- maxent(\n  x = selected_env_stack, \n  p = occurrences_matrix_clean\n)\n\n# Summary of the model\nsummary(maxent_model)\n\n# Predict the current distribution\ncurrent_distribution &lt;- predict(maxent_model, selected_env_stack)\n\n# Visualize the prediction\nplot(current_distribution, main = \"Predicted Current Distribution of Takakia\")\n\n# Save the predicted distribution as a GeoTIFF file\nwriteRaster(current_distribution, filename = \"Takakia_Current_Distribution.tif\", overwrite = TRUE)\n\n# Split data into training and testing sets\nset.seed(123)\ntrain_indices &lt;- sample(1:nrow(occurrences_matrix), size = 0.75 * nrow(occurrences_matrix))\ntrain_data &lt;- occurrences_matrix[train_indices, ]\ntest_data &lt;- occurrences_matrix[-train_indices, ]\n\n# Evaluate the model\neval &lt;- evaluate(maxent_model, p = train_data, a = test_data, x = selected_env_stack)\nprint(eval)\n\n# Plot the receiver operating characteristic (ROC) curve\nplot(eval, \"ROC\")\n\n# Perform Jackknife to evaluate the importance of each environmental variable\n# Use the 'maxent' model with jackknife = TRUE\njackknife_results &lt;- dismo::maxent(\n  x = selected_env_stack, \n  p = occurrences_matrix_clean,\n  jackknife = TRUE\n)\n\n# Extract Jackknife results from the 'maxent' object using the appropriate method\n# Jackknife results are contained in the model object itself, accessible by using the 'maxent' method:\njackknife_importance &lt;- jackknife_results@results\n\n# Display the Jackknife importance values for each variable\nprint(jackknife_importance)"
  },
  {
    "objectID": "data/Readme.html",
    "href": "data/Readme.html",
    "title": "GEO511_FinalProject",
    "section": "",
    "text": "Place any data needed by your analysis in this folder. Please do not store large files here. Then read in any data using the ‘data’ path. For example, read_csv(\"data/data.csv\")."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]